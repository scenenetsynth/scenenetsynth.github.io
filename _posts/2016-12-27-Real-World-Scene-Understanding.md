Last month saw a celebrated release of OpenAI universe, DeepMindLabs and TorchCraft from OpenAI, DeepMind and Facebook AI Research (FAIR). All of them are heavily investing on synthetic environments to develop and understand general intelligence systems that are on par or able to beat humans in such settings. Synthetic and gaming environments are appealing, with interest galvanised by the pioneering work of DeepMind in 2014, as they allow to factor out any chaos which might be present in the real world and provide simplified rulebook to interact, navigate and play. Moreover, built with a reward in the form of success or failure upon completing a task, they provide a natural way to measure and quantify performance and in a long-term intelligence, something that is a lot harder to do in real world. However, the hope is that experiments in synthetic environments will enlighten us to develop systems.


* Talk about what is SceneNet and what is new with SceneNet RGB-D.
* Raytracing - what is it? Why do we need it? What are the best ray tracers today and list each one of them with their limitations and benefits. Photon Mapping and why is it interesting? 
* Talk about camera response function, motion blur, lighting.
* How such images are going to be useful?

